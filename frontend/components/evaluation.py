import streamlit as st
import plotly.graph_objects as go
import plotly.express as px
import pandas as pd
from typing import Dict

def display_evaluation_metrics(evaluation_data: Dict):
    """
    Affiche les m√©triques d'√©valuation avec visualisations.
    
    Args:
        evaluation_data: Dictionnaire contenant les r√©sultats d'√©valuation
    """
    
    if not evaluation_data:
        st.warning("Aucune donn√©e d'√©valuation disponible")
        return
    
    eval_results = evaluation_data.get("evaluation", {})
    metadata = evaluation_data.get("metadata", {})
    
    # En-t√™te avec m√©tadonn√©es
    st.subheader("üìä M√©triques d'√âvaluation")
    
    col1, col2, col3 = st.columns(3)
    with col1:
        st.metric("Motifs totaux", metadata.get("total_patterns", 0))
    with col2:
        st.metric("Motifs √©chantillonn√©s", metadata.get("sampled_patterns", 0))
    with col3:
        st.metric("Feedbacks re√ßus", metadata.get("total_feedbacks", 0))
    
    st.markdown("---")
    
    # Score global
    overall_score = eval_results.get("overall_score", 0)
    st.subheader(f"üéØ Score Global: {overall_score:.2%}")
    
    # Jauge pour le score global
    fig_gauge = go.Figure(go.Indicator(
        mode="gauge+number",
        value=overall_score * 100,
        domain={'x': [0, 1], 'y': [0, 1]},
        title={'text': "Score Global (%)"},
        gauge={
            'axis': {'range': [None, 100]},
            'bar': {'color': "darkblue"},
            'steps': [
                {'range': [0, 33], 'color': "lightgray"},
                {'range': [33, 66], 'color': "gray"},
                {'range': [66, 100], 'color': "lightblue"}
            ],
            'threshold': {
                'line': {'color': "red", 'width': 4},
                'thickness': 0.75,
                'value': 80
            }
        }
    ))
    fig_gauge.update_layout(height=300)
    st.plotly_chart(fig_gauge, use_container_width=True)
    
    st.markdown("---")
    
    # Cr√©er des onglets pour les diff√©rentes m√©triques
    tab1, tab2, tab3, tab4, tab5 = st.tabs([
        "üìà Taux d'Acceptation",
        "üåà Diversit√©",
        "üì¶ Couverture",
        "üîí Stabilit√©",
        "‚è±Ô∏è Performance"
    ])
    
    # Onglet 1: Taux d'Acceptation
    with tab1:
        acceptance = eval_results.get("acceptance", {})
        
        col1, col2 = st.columns([2, 1])
        
        with col1:
            st.metric(
                "Taux d'Acceptation",
                f"{acceptance.get('acceptance_rate', 0):.2%}",
                help="Proportion de motifs aim√©s (likes) par rapport au total des feedbacks"
            )
            
            # Graphique en barres
            likes = acceptance.get("likes", 0)
            dislikes = acceptance.get("dislikes", 0)
            neutral = acceptance.get("neutral", 0)
            
            fig_feedback = go.Figure(data=[
                go.Bar(name='üëç Likes', x=['Feedback'], y=[likes], marker_color='green'),
                go.Bar(name='üëé Dislikes', x=['Feedback'], y=[dislikes], marker_color='red'),
                go.Bar(name='‚ö™ Neutral', x=['Feedback'], y=[neutral], marker_color='gray')
            ])
            fig_feedback.update_layout(
                title="Distribution des Feedbacks",
                barmode='group',
                height=300
            )
            st.plotly_chart(fig_feedback, use_container_width=True)
        
        with col2:
            st.metric("Total Feedbacks", acceptance.get("total_feedbacks", 0))
            st.metric("üëç Likes", likes)
            st.metric("üëé Dislikes", dislikes)
            st.metric("‚ö™ Neutral", neutral)
        
        st.info("""
        **Interpr√©tation:** Un taux d'acceptation √©lev√© (>70%) indique que les motifs √©chantillonn√©s 
        sont pertinents pour l'utilisateur. Un taux faible sugg√®re d'ajuster les poids d'√©chantillonnage.
        """)
    
    # Onglet 2: Diversit√©
    with tab2:
        diversity = eval_results.get("diversity", {})
        
        col1, col2, col3 = st.columns(3)
        with col1:
            st.metric(
                "Score de Diversit√©",
                f"{diversity.get('diversity_score', 0):.3f}",
                help="Distance de Jaccard moyenne entre motifs (0=identiques, 1=totalement diff√©rents)"
            )
        with col2:
            st.metric(
                "Items Uniques",
                diversity.get("unique_items_count", 0),
                help="Nombre d'items diff√©rents couverts par les motifs"
            )
        with col3:
            st.metric(
                "Longueur Moyenne",
                f"{diversity.get('average_pattern_length', 0):.1f}",
                help="Taille moyenne des motifs √©chantillonn√©s"
            )
        
        # Jauge de diversit√©
        fig_div = go.Figure(go.Indicator(
            mode="gauge+number+delta",
            value=diversity.get('diversity_score', 0) * 100,
            domain={'x': [0, 1], 'y': [0, 1]},
            title={'text': "Diversit√© (%)"},
            delta={'reference': 50},
            gauge={
                'axis': {'range': [None, 100]},
                'bar': {'color': "purple"},
                'steps': [
                    {'range': [0, 30], 'color': "lightgray"},
                    {'range': [30, 70], 'color': "lavender"},
                    {'range': [70, 100], 'color': "plum"}
                ],
            }
        ))
        fig_div.update_layout(height=300)
        st.plotly_chart(fig_div, use_container_width=True)
        
        st.info("""
        **Interpr√©tation:** Une diversit√© √©lev√©e (>0.7) signifie que les motifs sont tr√®s diff√©rents 
        les uns des autres, r√©duisant la redondance. Une faible diversit√© (<0.3) indique des motifs similaires.
        """)
    
    # Onglet 3: Couverture
    with tab3:
        coverage = eval_results.get("coverage", {})
        
        col1, col2, col3 = st.columns(3)
        with col1:
            st.metric(
                "Couverture Motifs",
                f"{coverage.get('pattern_coverage', 0):.2%}",
                help="Proportion de motifs √©chantillonn√©s par rapport au total"
            )
        with col2:
            st.metric(
                "Couverture Items",
                f"{coverage.get('item_coverage', 0):.2%}",
                help="Proportion d'items uniques couverts"
            )
        with col3:
            st.metric(
                "Couverture Support",
                f"{coverage.get('support_coverage', 0):.2%}",
                help="Somme des supports √©chantillonn√©s / total"
            )
        
        # Graphique de couverture
        coverage_data = pd.DataFrame({
            'M√©trique': ['Motifs', 'Items', 'Support'],
            'Couverture': [
                coverage.get('pattern_coverage', 0) * 100,
                coverage.get('item_coverage', 0) * 100,
                coverage.get('support_coverage', 0) * 100
            ]
        })
        
        fig_cov = px.bar(
            coverage_data,
            x='M√©trique',
            y='Couverture',
            title="Couverture par Type (%)",
            color='Couverture',
            color_continuous_scale='Blues'
        )
        fig_cov.update_layout(height=300, showlegend=False)
        st.plotly_chart(fig_cov, use_container_width=True)
        
        st.info("""
        **Interpr√©tation:** Une bonne couverture (>50%) assure que l'√©chantillon repr√©sente 
        bien le pool complet de motifs. Une couverture faible peut n√©cessiter d'augmenter k.
        """)
    
    # Onglet 4: Stabilit√©
    with tab4:
        stability = eval_results.get("stability", {})
        
        if stability.get("stability_score") is not None:
            col1, col2, col3 = st.columns(3)
            with col1:
                st.metric(
                    "Score de Stabilit√©",
                    f"{stability.get('stability_score', 0):.3f}",
                    help="Similarit√© moyenne entre √©chantillons avec diff√©rentes seeds (0=instable, 1=stable)"
                )
            with col2:
                st.metric(
                    "Similarit√© Moyenne",
                    f"{stability.get('mean_similarity', 0):.3f}"
                )
            with col3:
                st.metric(
                    "√âcart-Type",
                    f"{stability.get('std_similarity', 0):.3f}",
                    help="Variabilit√© des similarit√©s"
                )
            
            # Histogramme des similarit√©s
            similarities = stability.get("jaccard_similarities", [])
            if similarities:
                fig_stab = go.Figure(data=[go.Histogram(
                    x=similarities,
                    nbinsx=20,
                    marker_color='teal'
                )])
                fig_stab.update_layout(
                    title="Distribution des Similarit√©s de Jaccard",
                    xaxis_title="Similarit√©",
                    yaxis_title="Fr√©quence",
                    height=300
                )
                st.plotly_chart(fig_stab, use_container_width=True)
            
            st.info("""
            **Interpr√©tation:** Une stabilit√© √©lev√©e (>0.7) indique que l'algorithme produit 
            des r√©sultats reproductibles. Une faible stabilit√© (<0.3) sugg√®re une forte d√©pendance √† la seed.
            """)
        else:
            st.warning("Donn√©es de stabilit√© non disponibles")
    
    # Onglet 5: Performance
    with tab5:
        response_time = eval_results.get("response_time", {})
        
        if response_time.get("mean_time") is not None:
            col1, col2, col3, col4 = st.columns(4)
            with col1:
                st.metric(
                    "Temps Moyen",
                    f"{response_time.get('mean_time', 0):.3f}s"
                )
            with col2:
                st.metric(
                    "Temps Min",
                    f"{response_time.get('min_time', 0):.3f}s"
                )
            with col3:
                st.metric(
                    "Temps Max",
                    f"{response_time.get('max_time', 0):.3f}s"
                )
            with col4:
                st.metric(
                    "√âcart-Type",
                    f"{response_time.get('std_time', 0):.3f}s"
                )
            
            # Indicateur de performance
            mean_time = response_time.get('mean_time', 0)
            if mean_time < 2:
                perf_status = "üü¢ Excellent"
                perf_color = "green"
            elif mean_time < 5:
                perf_status = "üü° Bon"
                perf_color = "orange"
            else:
                perf_status = "üî¥ √Ä am√©liorer"
                perf_color = "red"
            
            st.markdown(f"### Performance: {perf_status}")
            
            # Barre de progression
            fig_perf = go.Figure(go.Indicator(
                mode="number+delta",
                value=mean_time,
                title={'text': "Temps de R√©ponse Moyen (s)"},
                delta={'reference': 2, 'relative': False},
                domain={'x': [0, 1], 'y': [0, 1]}
            ))
            fig_perf.update_layout(height=200)
            st.plotly_chart(fig_perf, use_container_width=True)
            
            st.info("""
            **Objectif:** < 2-3 secondes pour une exp√©rience interactive optimale. 
            Un temps sup√©rieur peut n√©cessiter une optimisation de l'algorithme ou une r√©duction de k.
            """)
        else:
            st.warning("Donn√©es de performance non disponibles")


def display_evaluation_summary(evaluation_data: Dict):
    """
    Affiche un r√©sum√© compact des m√©triques d'√©valuation.
    
    Args:
        evaluation_data: Dictionnaire contenant les r√©sultats d'√©valuation
    """
    if not evaluation_data:
        return
    
    eval_results = evaluation_data.get("evaluation", {})
    
    col1, col2, col3, col4, col5 = st.columns(5)
    
    with col1:
        acceptance_rate = eval_results.get("acceptance", {}).get("acceptance_rate", 0)
        st.metric("Acceptation", f"{acceptance_rate:.1%}")
    
    with col2:
        diversity = eval_results.get("diversity", {}).get("diversity_score", 0)
        st.metric("Diversit√©", f"{diversity:.2f}")
    
    with col3:
        coverage = eval_results.get("coverage", {}).get("pattern_coverage", 0)
        st.metric("Couverture", f"{coverage:.1%}")
    
    with col4:
        stability = eval_results.get("stability", {}).get("stability_score", 0)
        if stability:
            st.metric("Stabilit√©", f"{stability:.2f}")
        else:
            st.metric("Stabilit√©", "N/A")
    
    with col5:
        overall = eval_results.get("overall_score", 0)
        st.metric("Score Global", f"{overall:.1%}")
